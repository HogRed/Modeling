{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine Tuning with Optuna\n",
        "\n",
        "Notebook inspired by [Hands-On Machine Learning with Scikit-Learn and PyTorch](https://www.oreilly.com/library/view/hands-on-machine-learning/9798341607972/)."
      ],
      "metadata": {
        "id": "ZJafSy_963_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Classifier Code"
      ],
      "metadata": {
        "id": "PJNfkZ2aM86v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as T\n",
        "\n",
        "# set device depending on what's available\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "  device = 'mps'\n",
        "else:\n",
        "  device = 'cpu'\n",
        "\n",
        "\n",
        "# create tensor object we'll transform FashionMNIST data to\n",
        "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale = True)])\n",
        "\n",
        "# bring in train, test, valid data\n",
        "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
        "    root = 'datasets',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = toTensor\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root = 'datasets',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = toTensor\n",
        ")\n",
        "\n",
        "# reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# save back 5_000 from train to be reserved for validation\n",
        "train_data, valid_data = torch.utils.data.random_split(\n",
        "    train_and_valid_data,\n",
        "    [55_000, 5_000]\n",
        ")\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)\n",
        "valid_loader = DataLoader(valid_data, batch_size = 32)\n",
        "test_loader = DataLoader(test_data, batch_size = 32)\n",
        "\n",
        "from torch import nn\n",
        "# custom classification MLP w/ 2 hidden layers\n",
        "class ImageClassifier(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
        "    super().__init__()\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(n_inputs, n_hidden1),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_hidden1, n_hidden2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_hidden2, n_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.mlp(X)\n",
        "\n",
        "# train function to implement mb gd\n",
        "def train_mbgd(model, optimizer, criterion, train_loader, n_epochs):\n",
        "  model.train() # set training mode\n",
        "  for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "      # get batch\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      # mod pred\n",
        "      y_pred = model(X_batch)\n",
        "      # calc loss and tally\n",
        "      loss = criterion(y_pred, y_batch)\n",
        "      total_loss += loss.item()\n",
        "      # calc grads and do step\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    mean_loss = total_loss / len(train_loader)\n",
        "    if epoch % 10 == 0: # every ten epochs, print out loss\n",
        "      print(f'Epoch {epoch + 1}, Loss: {mean_loss}')\n",
        "\n",
        "## create evaluation function\n",
        "def evaluate(model, data_loader, metric, aggregate = torch.mean):\n",
        "  model.eval() # change model mode to evaluation (no gradient work)\n",
        "  metrics = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X_batch, y_batch in data_loader:\n",
        "      # move data to GPU / cuda\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      y_pred = model(X_batch)\n",
        "      metric_val = metric(y_pred, y_batch)\n",
        "      metrics.append(metric_val)\n",
        "\n",
        "  # retrun agg met over all batches\n",
        "  return aggregate(torch.stack(metrics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7p3csqqRM-M0",
        "outputId": "731e608e-061c-47b1-ef60-6298ca87bffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 16.2MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 275kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.13MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 21.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "fZwS2mmpMZjt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4Sv__W1MLGE",
        "outputId": "86cd3dff-49da-46d7-b146-b081a610b4e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n",
            "Downloading optuna-4.6.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.7/404.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, optuna\n",
            "Successfully installed colorlog-6.10.1 optuna-4.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tySKVEcNji1",
        "outputId": "b7c31c35-8db9-4483-a9ac-9e607df505c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import torchmetrics\n",
        "\n",
        "# define function that will be called by Optuna\n",
        "# function takes trial object and asks\n",
        "# Optuna for hyperparam vals;\n",
        "# these vals will be used to train model\n",
        "def objective(trial):\n",
        "  # setting log to true will have Optuna sample a much larger range of\n",
        "  # values by using log distribution\n",
        "  learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
        "  n_hidden = trial.suggest_int('n_hidden', 20, 300)\n",
        "\n",
        "  model = ImageClassifier(n_inputs = 1 * 28 * 28, n_hidden1 = n_hidden,\n",
        "                          n_hidden2 = n_hidden, n_classes = 10).to(device)\n",
        "\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  train_mbgd(model, optimizer, criterion, train_loader, n_epochs = 100)\n",
        "\n",
        "  # evaluate on validation set\n",
        "  accuracy_val = evaluate(model, valid_loader,\n",
        "                        lambda y_pred, y_batch: (y_pred.argmax(dim=1)\n",
        "                        == y_batch).float().mean(),\n",
        "                        aggregate = torch.mean)\n",
        "  return accuracy_val"
      ],
      "metadata": {
        "id": "4sKTxbeJMg_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "FZUZMqX8OG_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# need to create study obj to begin tuning\n",
        "torch.manual_seed(42)\n",
        "# Tree-structured Parzen Estimator; sequential based optimization algo\n",
        "sampler = optuna.samplers.TPESampler(seed=42)\n",
        "\n",
        "# higher score better... therefore, maximize\n",
        "study = optuna.create_study(sampler=sampler, direction=\"maximize\")\n",
        "\n",
        "study.optimize(objective, n_trials=5)"
      ],
      "metadata": {
        "id": "d2Agg7I_OIiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## look at best hyperparam found, and corresponding val accuracy\n",
        "study.best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhQR_B6_QS8_",
        "outputId": "9d367c0f-42d0-4e36-d0de-a45a2aa4c36b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.00031489116479568613, 'n_hidden': 287}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fw6H2WqTfkJ",
        "outputId": "fc3328da-6d38-4b80-c982-380a92fae92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8320063948631287"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model on Full Training Data"
      ],
      "metadata": {
        "id": "EyS1TtyfTlQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make data loader out of train_and_valid_data\n",
        "train_loader = DataLoader(train_and_valid_data,\n",
        "                          batch_size = 32,\n",
        "                          shuffle = True)"
      ],
      "metadata": {
        "id": "kWuLOlx4Y6mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = ImageClassifier(n_inputs = 1 * 28 * 28, n_hidden1 = 287,\n",
        "                          n_hidden2 = 287, n_classes = 10).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(new_model.parameters(), lr = 0.00031489116479568613)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_mbgd(new_model, optimizer, criterion, train_loader, n_epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uzfBnZWToGV",
        "outputId": "98fedc8d-2acb-4981-96ef-0b6d589d53d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.271330679066976\n",
            "Epoch 11, Loss: 0.9710857071558634\n",
            "Epoch 21, Loss: 0.7233449332078298\n",
            "Epoch 31, Loss: 0.6262222062905629\n",
            "Epoch 41, Loss: 0.5675503201087316\n",
            "Epoch 51, Loss: 0.5288081739107767\n",
            "Epoch 61, Loss: 0.5019134725729625\n",
            "Epoch 71, Loss: 0.48193759031295774\n",
            "Epoch 81, Loss: 0.46643048729896547\n",
            "Epoch 91, Loss: 0.4541492882847786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model on test set\n",
        "new_model.eval()\n",
        "\n",
        "accuracy_test = evaluate(new_model, test_loader,\n",
        "                        lambda y_pred, y_batch: (y_pred.argmax(dim=1)\n",
        "                        == y_batch).float().mean(),\n",
        "                        aggregate = torch.mean)\n",
        "\n",
        "print(f'Accuracy on test set: {accuracy_test}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIe_cF8vUBVM",
        "outputId": "5c768dae-2cf1-4748-e99c-2a11fc05b12e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set: 0.8308705687522888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving and Loading Models in PyTorch"
      ],
      "metadata": {
        "id": "ThiD5PGXRjam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## save model info in state dictionary\n",
        "model_data = {\n",
        "    'model_state_dict': new_model.state_dict(),\n",
        "    'model_hyperparameters': {\n",
        "        'n_inputs': 1 * 28 * 28,\n",
        "        'n_hidden1': 287,\n",
        "        'n_hidden2': 287,\n",
        "        'n_classes': 10\n",
        "    }\n",
        "}\n",
        "\n",
        "# save model\n",
        "torch.save(model_data, 'model_fashion_mnist.pth')"
      ],
      "metadata": {
        "id": "tqnBqtQTRmFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load in dictionary, construct model, and load state dictionary into mod\n",
        "loaded_data = torch.load('model_fashion_mnist.pth', weights_only = True)\n",
        "\n",
        "new_model = ImageClassifier(**loaded_data['model_hyperparameters'])\n",
        "new_model.load_state_dict(loaded_data['model_state_dict'])\n",
        "\n",
        "new_model.eval() # ready to rock and roll!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfFic07YVjgr",
        "outputId": "4424556d-c0cc-43eb-f538-c934104444fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ImageClassifier(\n",
              "  (mlp): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=287, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Linear(in_features=287, out_features=287, bias=True)\n",
              "    (4): ReLU()\n",
              "    (5): Linear(in_features=287, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}