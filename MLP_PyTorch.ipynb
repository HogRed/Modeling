{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Load in Packages and UCI Bike Share Data\n",
        "\n",
        "\n",
        "UCI Data can be found [here](https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset).\n",
        "\n",
        "Notebook inspired by [Hands-On Machine Learning with Scikit-Learn and PyTorch](https://www.oreilly.com/library/view/hands-on-machine-learning/9798341607972/)."
      ],
      "metadata": {
        "id": "5JYeFUMWT7RE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "gST-ILypSAM4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dat = pd.read_csv('day.csv')"
      ],
      "metadata": {
        "id": "lw9zRbs_SuSQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dat.drop(columns = ['cnt', 'instant','dteday'])\n",
        "y = dat['cnt']"
      ],
      "metadata": {
        "id": "VVg_yixFjZj9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Train, Val, Test Splits"
      ],
      "metadata": {
        "id": "Y6R5j-ZtT-U7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create train & test splits\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 501)\n",
        "\n",
        "# create validation split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
        "                                                    test_size = 0.2,\n",
        "                                                    random_state = 501)"
      ],
      "metadata": {
        "id": "Tlcda4yMSzEP"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# center and scale X data\n",
        "X_train = torch.FloatTensor(X_train.to_numpy())\n",
        "X_valid = torch.FloatTensor(X_val.to_numpy())\n",
        "X_test = torch.FloatTensor(X_test.to_numpy())\n",
        "\n",
        "means = X_train.mean(dim=0, keepdims=True)\n",
        "stds = X_train.std(dim=0, keepdims=True)\n",
        "\n",
        "X_train = (X_train - means) / stds\n",
        "X_valid = (X_valid - means) / stds\n",
        "X_test = (X_test - means) / stds"
      ],
      "metadata": {
        "id": "fQOws-RCS9cK"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# center and scale y data\n",
        "y_train = torch.FloatTensor(y_train.to_numpy()).reshape(-1,1)\n",
        "y_valid = torch.FloatTensor(y_val.to_numpy()).reshape(-1,1)\n",
        "y_test = torch.FloatTensor(y_test.to_numpy()).reshape(-1,1)\n",
        "\n",
        "y_mean = y_train.mean(dim=0, keepdims=True)\n",
        "y_std  = y_train.std(dim=0, keepdims=True)\n",
        "\n",
        "y_train = (y_train - y_mean) / y_std\n",
        "y_valid = (y_valid - y_mean) / y_std\n",
        "y_test  = (y_test  - y_mean) / y_std"
      ],
      "metadata": {
        "id": "BlXrp2FqTyLp"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Gradient Descent Function"
      ],
      "metadata": {
        "id": "fKOTIz2yUCoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs):\n",
        "  for epoch in range(n_epochs):\n",
        "    y_pred = model(X_train)\n",
        "    loss = criterion(y_pred, y_train) # get loss val\n",
        "    loss.backward() # calc grads\n",
        "    optimizer.step() # take grad desc step\n",
        "    optimizer.zero_grad() # zero out grads for next pass\n",
        "    print(f'Epoch {epoch + 1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "id": "DRnBJD0wUFMJ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression MLP"
      ],
      "metadata": {
        "id": "bL2G6oBSUwEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_features = X_train.shape[1] # get cols"
      ],
      "metadata": {
        "id": "npMaQsRgVDkm"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "torch.manual_seed(501)\n",
        "# (input, output) for each layer\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 1) # 1 output --> regression val\n",
        ")"
      ],
      "metadata": {
        "id": "yb0WX1YoUxJn"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model"
      ],
      "metadata": {
        "id": "W1Ij8yuMVLIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set model training params\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "id": "dPYm8OIuVMCQ"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_bgd(model, optimizer, criterion, X_train, y_train, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1teeWglDWjPv",
        "outputId": "a0304409-8a35-47d0-a105-52d8a971d237"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0571339130401611\n",
            "Epoch 2, Loss: 1.0426732301712036\n",
            "Epoch 3, Loss: 1.0291247367858887\n",
            "Epoch 4, Loss: 1.0163812637329102\n",
            "Epoch 5, Loss: 1.0043340921401978\n",
            "Epoch 6, Loss: 0.9928900003433228\n",
            "Epoch 7, Loss: 0.9820040464401245\n",
            "Epoch 8, Loss: 0.9715561270713806\n",
            "Epoch 9, Loss: 0.9614793658256531\n",
            "Epoch 10, Loss: 0.951737642288208\n",
            "Epoch 11, Loss: 0.9422871470451355\n",
            "Epoch 12, Loss: 0.9330822229385376\n",
            "Epoch 13, Loss: 0.9240773916244507\n",
            "Epoch 14, Loss: 0.9152446985244751\n",
            "Epoch 15, Loss: 0.9065364599227905\n",
            "Epoch 16, Loss: 0.897942841053009\n",
            "Epoch 17, Loss: 0.889440655708313\n",
            "Epoch 18, Loss: 0.8810222744941711\n",
            "Epoch 19, Loss: 0.872648298740387\n",
            "Epoch 20, Loss: 0.8643302917480469\n",
            "Epoch 21, Loss: 0.856031596660614\n",
            "Epoch 22, Loss: 0.8477593660354614\n",
            "Epoch 23, Loss: 0.8394768238067627\n",
            "Epoch 24, Loss: 0.8311606049537659\n",
            "Epoch 25, Loss: 0.8228361010551453\n",
            "Epoch 26, Loss: 0.8144875168800354\n",
            "Epoch 27, Loss: 0.8061072826385498\n",
            "Epoch 28, Loss: 0.7976723313331604\n",
            "Epoch 29, Loss: 0.7891790270805359\n",
            "Epoch 30, Loss: 0.780667245388031\n",
            "Epoch 31, Loss: 0.7720850706100464\n",
            "Epoch 32, Loss: 0.7634281516075134\n",
            "Epoch 33, Loss: 0.7547131180763245\n",
            "Epoch 34, Loss: 0.7459244132041931\n",
            "Epoch 35, Loss: 0.7370729446411133\n",
            "Epoch 36, Loss: 0.7281751036643982\n",
            "Epoch 37, Loss: 0.719225287437439\n",
            "Epoch 38, Loss: 0.7102057933807373\n",
            "Epoch 39, Loss: 0.7011221647262573\n",
            "Epoch 40, Loss: 0.6919730305671692\n",
            "Epoch 41, Loss: 0.6827549338340759\n",
            "Epoch 42, Loss: 0.6734758615493774\n",
            "Epoch 43, Loss: 0.6641635298728943\n",
            "Epoch 44, Loss: 0.6548008918762207\n",
            "Epoch 45, Loss: 0.6453865170478821\n",
            "Epoch 46, Loss: 0.6359192132949829\n",
            "Epoch 47, Loss: 0.6264150738716125\n",
            "Epoch 48, Loss: 0.616876482963562\n",
            "Epoch 49, Loss: 0.6073129773139954\n",
            "Epoch 50, Loss: 0.5977334976196289\n",
            "Epoch 51, Loss: 0.5881495475769043\n",
            "Epoch 52, Loss: 0.5785461664199829\n",
            "Epoch 53, Loss: 0.5689376592636108\n",
            "Epoch 54, Loss: 0.5593392252922058\n",
            "Epoch 55, Loss: 0.5497488379478455\n",
            "Epoch 56, Loss: 0.5401756167411804\n",
            "Epoch 57, Loss: 0.5306236743927002\n",
            "Epoch 58, Loss: 0.5211052894592285\n",
            "Epoch 59, Loss: 0.5116279721260071\n",
            "Epoch 60, Loss: 0.502204418182373\n",
            "Epoch 61, Loss: 0.4928329288959503\n",
            "Epoch 62, Loss: 0.4835200309753418\n",
            "Epoch 63, Loss: 0.47427257895469666\n",
            "Epoch 64, Loss: 0.46509310603141785\n",
            "Epoch 65, Loss: 0.45599159598350525\n",
            "Epoch 66, Loss: 0.44698119163513184\n",
            "Epoch 67, Loss: 0.43807727098464966\n",
            "Epoch 68, Loss: 0.42928647994995117\n",
            "Epoch 69, Loss: 0.42060789465904236\n",
            "Epoch 70, Loss: 0.4120441973209381\n",
            "Epoch 71, Loss: 0.4036028981208801\n",
            "Epoch 72, Loss: 0.39530548453330994\n",
            "Epoch 73, Loss: 0.3871501088142395\n",
            "Epoch 74, Loss: 0.37914228439331055\n",
            "Epoch 75, Loss: 0.37126806378364563\n",
            "Epoch 76, Loss: 0.36353427171707153\n",
            "Epoch 77, Loss: 0.3559555411338806\n",
            "Epoch 78, Loss: 0.34852415323257446\n",
            "Epoch 79, Loss: 0.34123316407203674\n",
            "Epoch 80, Loss: 0.334095299243927\n",
            "Epoch 81, Loss: 0.32712551951408386\n",
            "Epoch 82, Loss: 0.32031288743019104\n",
            "Epoch 83, Loss: 0.31366750597953796\n",
            "Epoch 84, Loss: 0.30718934535980225\n",
            "Epoch 85, Loss: 0.30088528990745544\n",
            "Epoch 86, Loss: 0.29475146532058716\n",
            "Epoch 87, Loss: 0.28878650069236755\n",
            "Epoch 88, Loss: 0.28297993540763855\n",
            "Epoch 89, Loss: 0.2773416042327881\n",
            "Epoch 90, Loss: 0.2718714475631714\n",
            "Epoch 91, Loss: 0.2665688991546631\n",
            "Epoch 92, Loss: 0.26141953468322754\n",
            "Epoch 93, Loss: 0.2564164400100708\n",
            "Epoch 94, Loss: 0.2515583634376526\n",
            "Epoch 95, Loss: 0.24684764444828033\n",
            "Epoch 96, Loss: 0.24228103458881378\n",
            "Epoch 97, Loss: 0.2378511130809784\n",
            "Epoch 98, Loss: 0.23354139924049377\n",
            "Epoch 99, Loss: 0.22935204207897186\n",
            "Epoch 100, Loss: 0.22528967261314392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-Batch GD Using DataLoaders"
      ],
      "metadata": {
        "id": "L8MFgFK5hlMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set device depending on what's available\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "  device = 'mps'\n",
        "else:\n",
        "  device = 'cpu'"
      ],
      "metadata": {
        "id": "xmNgn81nh2bx"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle = True)"
      ],
      "metadata": {
        "id": "3aJHM9Beiw7c"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(501)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(n_features, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 1) # 1 output --> regression val\n",
        ")\n",
        "\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "V4lzdsInhnmz"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.MSELoss()\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "id": "YhhZlVvVj51y"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train function to implement mb gd\n",
        "def train_mbgd(model, optimizer, criterion, train_loader, n_epochs):\n",
        "  model.train() # set training mode\n",
        "  for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "      # get batch\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      # mod pred\n",
        "      y_pred = model(X_batch)\n",
        "      # calc loss and tally\n",
        "      loss = criterion(y_pred, y_batch)\n",
        "      total_loss += loss.item()\n",
        "      # calc grads and do step\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    mean_loss = total_loss / len(train_loader)\n",
        "    if epoch % 10 == 0: # every ten epochs, print out loss\n",
        "      print(f'Epoch {epoch + 1}, Loss: {mean_loss}')"
      ],
      "metadata": {
        "id": "x8Y8tGQmiNAu"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mbgd(model, optimizer, criterion, train_loader, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEaVMFQ-ipdX",
        "outputId": "7cdebc6b-2d31-42bb-f442-be9fcf748b7b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9749118367830912\n",
            "Epoch 11, Loss: 0.10588822265466054\n",
            "Epoch 21, Loss: 0.043283493568499885\n",
            "Epoch 31, Loss: 0.027103760838508607\n",
            "Epoch 41, Loss: 0.018806432994703453\n",
            "Epoch 51, Loss: 0.014053460645178954\n",
            "Epoch 61, Loss: 0.010648593616982302\n",
            "Epoch 71, Loss: 0.008801982241372268\n",
            "Epoch 81, Loss: 0.007529840804636478\n",
            "Epoch 91, Loss: 0.006357607307533423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model"
      ],
      "metadata": {
        "id": "L20TTjVqkoNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create evaluation function\n",
        "def evaluate(model, data_loader, metric, aggregate = torch.mean):\n",
        "  model.eval() # change model mode to evaluation (no gradient work)\n",
        "  metrics = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X_batch, y_batch in data_loader:\n",
        "      # move data to GPU / cuda\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      y_pred = model(X_batch)\n",
        "      metric_val = metric(y_pred, y_batch)\n",
        "      metrics.append(metric_val)\n",
        "\n",
        "  # retrun agg met over all batches\n",
        "  return aggregate(torch.stack(metrics))"
      ],
      "metadata": {
        "id": "fGswoeABkpm1"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up validation data loader\n",
        "# don't typically use shuffle in evaluation so it's deterministic\n",
        "# and the ordering is stable\n",
        "valid_dataset = TensorDataset(X_valid, y_valid)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle = False)"
      ],
      "metadata": {
        "id": "3MkO4hzTlji7"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RMSE on validation data\n",
        "evaluate(model, valid_loader, criterion,\n",
        "         aggregate = lambda metrics: torch.sqrt(torch.mean(metrics)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3t-wcYRlgWQ",
        "outputId": "aeba05ad-45b1-4b53-d68c-80ad648c5dcc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1094, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE on validation data\n",
        "evaluate(model, valid_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmp6VNV4l6ea",
        "outputId": "64b3b223-4a64-4611-b006-f62d5586eb3a"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0120, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    }
  ]
}