{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Building Custom Image Classifier in PyTorch\n",
        "\n",
        "Notebook inspired by [Hands-On Machine Learning with Scikit-Learn and PyTorch](https://www.oreilly.com/library/view/hands-on-machine-learning/9798341607972/)."
      ],
      "metadata": {
        "id": "_VPYB_PoPSF3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load in Dataset"
      ],
      "metadata": {
        "id": "aBwk40nSHtLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set device depending on what's available\n",
        "if torch.cuda.is_available():\n",
        "  device = 'cuda'\n",
        "elif torch.backends.mps.is_available():\n",
        "  device = 'mps'\n",
        "else:\n",
        "  device = 'cpu'"
      ],
      "metadata": {
        "id": "0JV3ghiJMKl5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L7oVUcaCHqsy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms.v2 as T\n",
        "\n",
        "# create tensor object we'll transform FashionMNIST data to\n",
        "toTensor = T.Compose([T.ToImage(), T.ToDtype(torch.float32, scale = True)])\n",
        "\n",
        "# bring in train, test, valid data\n",
        "train_and_valid_data = torchvision.datasets.FashionMNIST(\n",
        "    root = 'datasets',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform = toTensor\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.FashionMNIST(\n",
        "    root = 'datasets',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = toTensor\n",
        ")\n",
        "\n",
        "# reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# save back 5_000 from train to be reserved for validation\n",
        "train_data, valid_data = torch.utils.data.random_split(\n",
        "    train_and_valid_data,\n",
        "    [55_000, 5_000]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create data loaders\n",
        "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)\n",
        "valid_loader = DataLoader(valid_data, batch_size = 32)\n",
        "test_loader = DataLoader(test_data, batch_size = 32)"
      ],
      "metadata": {
        "id": "jh51yB1sI2dL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# look at first image in training set\n",
        "X_sample, y_sample = train_data[0]\n",
        "\n",
        "X_sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6dPZ20CJAeo",
        "outputId": "75a84a78-26ed-4107-f03d-8a20aa6d0f50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_sample.dtype # check type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5EEbkioJG3J",
        "outputId": "8412835b-8881-4429-ae70-d91bcc407bdf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check class of sample\n",
        "train_and_valid_data.classes[y_sample]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5dL52QF6JZS9",
        "outputId": "b0881493-78c7-4f15-c071-6adb1b446394"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ankle boot'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Classifier"
      ],
      "metadata": {
        "id": "aYWV54AMJd8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "# custom classification MLP w/ 2 hidden layers\n",
        "class ImageClassifier(nn.Module):\n",
        "  def __init__(self, n_inputs, n_hidden1, n_hidden2, n_classes):\n",
        "    super().__init__()\n",
        "    self.mlp = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(n_inputs, n_hidden1),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_hidden1, n_hidden2),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(n_hidden2, n_classes)\n",
        "    )\n",
        "\n",
        "  def forward(self, X):\n",
        "    return self.mlp(X)"
      ],
      "metadata": {
        "id": "h8MYvw4MJeyy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# create model instance\n",
        "model = ImageClassifier(\n",
        "    n_inputs = 28 * 28,\n",
        "    n_hidden1 = 400,\n",
        "    n_hidden2 = 200,\n",
        "    n_classes = 10\n",
        ")\n",
        "\n",
        "# use cross entropy loss for multi-class classification loss\n",
        "xentropy = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "4jI2-NUbJ9SW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set model training params\n",
        "learning_rate = 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "n_epochs = 100"
      ],
      "metadata": {
        "id": "kgyoPcD2K8UZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train function to implement mb gd\n",
        "def train_mbgd(model, optimizer, criterion, train_loader, n_epochs):\n",
        "  model.train() # set training mode\n",
        "  for epoch in range(n_epochs):\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "      # get batch\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      # mod pred\n",
        "      y_pred = model(X_batch)\n",
        "      # calc loss and tally\n",
        "      loss = criterion(y_pred, y_batch)\n",
        "      total_loss += loss.item()\n",
        "      # calc grads and do step\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    mean_loss = total_loss / len(train_loader)\n",
        "    if epoch % 10 == 0: # every ten epochs, print out loss\n",
        "      print(f'Epoch {epoch + 1}, Loss: {mean_loss}')"
      ],
      "metadata": {
        "id": "31aDss7tLZLo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device) # Move model to the correct device\n",
        "train_mbgd(model, optimizer, criterion, train_loader, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMxekwI_LcUz",
        "outputId": "15af7828-0997-4592-fa82-f09b04ea2fa8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0793743771373567\n",
            "Epoch 11, Loss: 0.3632791165247291\n",
            "Epoch 21, Loss: 0.2936345736055682\n",
            "Epoch 31, Loss: 0.24963734634849066\n",
            "Epoch 41, Loss: 0.21416325257238328\n",
            "Epoch 51, Loss: 0.1848576282665194\n",
            "Epoch 61, Loss: 0.1579446381330707\n",
            "Epoch 71, Loss: 0.13501447004576525\n",
            "Epoch 81, Loss: 0.11510268070612054\n",
            "Epoch 91, Loss: 0.09713919390233504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "8jfQoe6xUA5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## create evaluation function\n",
        "def evaluate(model, data_loader, metric, aggregate = torch.mean):\n",
        "  model.eval() # change model mode to evaluation (no gradient work)\n",
        "  metrics = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X_batch, y_batch in data_loader:\n",
        "      # move data to GPU / cuda\n",
        "      X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "      y_pred = model(X_batch)\n",
        "      metric_val = metric(y_pred, y_batch)\n",
        "      metrics.append(metric_val)\n",
        "\n",
        "  # retrun agg met over all batches\n",
        "  return aggregate(torch.stack(metrics))"
      ],
      "metadata": {
        "id": "QxUblQmUSFT-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-p2en6qNS-km",
        "outputId": "94ab610f-b440-4a69-b7b1-7d79f959e6f0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (25.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from torchmetrics) (2.9.0+cu126)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->torchmetrics) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use accuracy metric to evaluate predictive ability\n",
        "import torchmetrics\n",
        "accuracy = torchmetrics.Accuracy(task = 'multiclass', num_classes = 10).to(device)"
      ],
      "metadata": {
        "id": "i7hXATraSKxj"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy on validation data\n",
        "# calc batch-wise accuracy w/ lambda func\n",
        "# get average of batches via aggregate\n",
        "accuracy_val = evaluate(model, valid_loader,\n",
        "                        lambda y_pred, y_batch: (y_pred.argmax(dim=1)\n",
        "                        == y_batch).float().mean(),\n",
        "                        aggregate = torch.mean)\n",
        "\n",
        "print(f'Validation Accuracy: {accuracy_val.item()*100:.4f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfvckIFJSLMB",
        "outputId": "64289b92-d256-4b22-af65-2b57279ee665"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 88.7938%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict with New Images"
      ],
      "metadata": {
        "id": "5t0563dKUCSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set model to evaluate mode (no training)\n",
        "model.eval()\n",
        "\n",
        "# get batch\n",
        "X_new, y_new = next(iter(valid_loader))\n",
        "\n",
        "# grab first three in batch\n",
        "X_new = X_new[:3].to(device)"
      ],
      "metadata": {
        "id": "HG0Pq6q4UDij"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_pred_logits = model(X_new)\n",
        "\n",
        "# grab index of the largets logit model predicts\n",
        "y_pred = y_pred_logits.argmax(dim=1)\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCN1NLryUXN7",
        "outputId": "c9000f0f-7532-43c6-d7cd-5ece99e1246d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 4, 2], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# grab labels predicted via list comp\n",
        "[train_and_valid_data.classes[i] for i in y_pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8cb74TsUj5G",
        "outputId": "fcda4918-82d9-4d14-8228-bbad9ef2bc85"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sneaker', 'Coat', 'Pullover']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get mods estimated probs\n",
        "import torch.nn.functional as F\n",
        "\n",
        "y_proba = F.softmax(y_pred_logits, dim = 1)\n",
        "\n",
        "y_proba.round(decimals = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXIejeunU9Hf",
        "outputId": "c956b4e2-4ec6-4509-d26b-82b9a01b64ac"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9970, 0.0000,\n",
              "         0.0030],\n",
              "        [0.0000, 0.0000, 0.0200, 0.0000, 0.9800, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "         0.0000],\n",
              "        [0.0000, 0.0000, 0.9620, 0.0000, 0.0030, 0.0000, 0.0350, 0.0000, 0.0000,\n",
              "         0.0000]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# largest prob value predicted for each instance\n",
        "[max(i) for i in y_proba]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy9gqFoMVJi3",
        "outputId": "f52c2c9e-b3d7-45cd-862e-3d03289aced2"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.9968, device='cuda:0'),\n",
              " tensor(0.9795, device='cuda:0'),\n",
              " tensor(0.9619, device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get largest predicted probability and index of that probability's pos in\n",
        "# y_proba\n",
        "for i in y_proba:\n",
        "  print(i.max(), i.argmax())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2MluKC-VXDR",
        "outputId": "d724611e-f2d2-4ed7-eece-309195f9d13f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9968, device='cuda:0') tensor(7, device='cuda:0')\n",
            "tensor(0.9795, device='cuda:0') tensor(4, device='cuda:0')\n",
            "tensor(0.9619, device='cuda:0') tensor(2, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mod top-k preds\n",
        "y_top4_logits, y_top4_indices = torch.topk(\n",
        "    y_pred_logits,\n",
        "    k = 4,\n",
        "    dim = 1\n",
        ")\n",
        "\n",
        "# pass through softmax\n",
        "y_top4_probas = F.softmax(y_top4_logits, dim = 1)\n",
        "\n",
        "y_top4_probas.round(decimals = 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX-IMtuFWaEO",
        "outputId": "bff76702-e8c9-4a7d-bbc1-5963785caaa4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9970, 0.0030, 0.0000, 0.0000],\n",
              "        [0.9800, 0.0200, 0.0000, 0.0000],\n",
              "        [0.9620, 0.0350, 0.0030, 0.0000]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# indices of top 4 preds\n",
        "y_top4_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNeac-Y6Wrv8",
        "outputId": "0984c400-5db1-4b65-ff0d-dd9d58253eb2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7, 9, 5, 8],\n",
              "        [4, 2, 6, 8],\n",
              "        [2, 6, 4, 0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    }
  ]
}