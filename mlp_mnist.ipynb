{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_jeQy4REfgq"
      },
      "source": [
        "# Multilayer Perceptron (MLP) for MNIST Dataset\n",
        "\n",
        "In this notebook, we'll explore how to train a Multilayer Perceptron (MLP) on the popular MNIST dataset, which contains grayscale images of handwritten digits (0-9).\n",
        "\n",
        "A MLP is one of the most basic types of neural networks that you will encounter. They operate in a feed-forward (FFNN) fashion, with no sort of recurrent operation present. They are oftentimes called \"vanilla\" neural networks, due to them being thought of as a default style of network. They are also often called dense neural networks, due to the fact that the neurons are commonly fully connected to each other between hidden layers.\n",
        "\n",
        "Notebook inspired by [Generative Deep Learning: Teaching Machines to Paint, Write, Compose and Play](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1eqYgTDBEfgs"
      },
      "outputs": [],
      "source": [
        "# PACKAGE IMPORTS\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models, optimizers, utils, datasets\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "oEiMTL0rEfgt"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XdyJiAuMEfgt"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10 # Constant; digits 0 - 9\n",
        "BATCH_SIZE = 32 # size of mini-batch\n",
        "NUM_EPOCHS = 10 # full passes through data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO9SV1UIEfgt"
      },
      "source": [
        "\n",
        "## 1. Prepare the Data\n",
        "\n",
        "We will load the MNIST dataset, which contains 60,000 training images and 10,000 test images of handwritten digits. Each image is 28x28 pixels, and the task is to classify them into 10 classes (digits 0-9).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcILgyBNEfgt",
        "outputId": "3d3af899-d1a6-4c9b-90c8-9ba457c0b7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (60000, 784)\n",
            "Training labels shape: (60000, 10)\n",
            "\n",
            "Test data shape: (10000, 784)\n",
            "Test labels shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to have pixel values between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# -1 effectively tells Python to ignore batch dimension\n",
        "# 28*28 is flattening the image into a 1D vector\n",
        "x_train = x_train.reshape(-1, 28 * 28)\n",
        "x_test = x_test.reshape(-1, 28 * 28)\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Display train dat & label shape\n",
        "print(f\"Training data shape: {x_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "\n",
        "# Spacing\n",
        "print()\n",
        "\n",
        "# Display test dat & label shape\n",
        "print(f\"Test data shape: {x_test.shape}\")\n",
        "print(f\"Test labels shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGHHhnRWEfgt",
        "outputId": "1d16e8ed-3e4f-49f1-ade1-dbb866ded428"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Pixel Values:\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            "  0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            "  0.96862745 0.49803922 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            "  0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.19215687\n",
            "  0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            "  0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            "  0.96862745 0.94509804 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            "  0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04313726\n",
            "  0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.13725491 0.94509804\n",
            "  0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            "  0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            "  0.5882353  0.10588235 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            "  0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.15294118 0.5803922\n",
            "  0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.07058824 0.67058825\n",
            "  0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            "  0.3137255  0.03529412 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.53333336 0.99215686\n",
            "  0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "\n",
            "Label for first entry:\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Set NumPy to print the entire array\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "# Normalized pixel values\n",
        "print('Normalized Pixel Values:')\n",
        "print(x_train[:1])\n",
        "\n",
        "print() # Spacing\n",
        "\n",
        "# First entry label\n",
        "print('Label for first entry:')\n",
        "print(y_train[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pti3LWjwEfgt"
      },
      "source": [
        "\n",
        "## 2. Build the Model\n",
        "We will build a simple Multilayer Perceptron (MLP) model with the following architecture:\n",
        "- Input layer: 784 (28x28) input neurons (one for each pixel in the MNIST image).\n",
        "- Two hidden layers with ReLU activation.\n",
        "- Output layer with 10 neurons (one for each class) using softmax activation.\n",
        "\n",
        "Here's how we can define this model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FGvW1xHTEfgu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "1aa2bbd6-8ba7-4ea3-f1e7-fa9efe556b40"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the MLP model\n",
        "model = Sequential([\n",
        "    Input(shape = (28*28,)),\n",
        "    # First hidden layer with 128 units\n",
        "    Dense(128, activation='relu'),\n",
        "    # Second hidden layer with 64 units\n",
        "    Dense(64, activation='relu'),\n",
        "    # Output layer with 10 classes (digits 0-9)\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with categorical crossentropy and an optimizer\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "hfyia5fPEfgu"
      },
      "source": [
        "## 3. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9pkGYrN3Efgu"
      },
      "outputs": [],
      "source": [
        "# Set up optimizer for backpropogation\n",
        "opt = optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "# Compile model - get it ready for training\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=opt, metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzqx2CtyEfgu",
        "outputId": "d0878a27-940f-45d2-f449-85f93043a51e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.8483 - loss: 0.5366\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1321\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9744 - loss: 0.0856\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.0649\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0481\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0378\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0311\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0251\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0186\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0178\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787af5e52170>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Fit model\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=BATCH_SIZE, # batch size for each mini-batch of data\n",
        "          epochs=NUM_EPOCHS, # 10 pass-throughs of the full data\n",
        "          shuffle=True # Shuffle data for better training\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "bv8uOT5_Efgu"
      },
      "source": [
        "## 4. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2YzCJ90Efgu",
        "outputId": "f30f0d9c-c622-456a-9ae2-82a485c36bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9751 - loss: 0.0931\n",
            "Categorical Cross-Entropy Loss: 0.08521047234535217\n",
            "Accuracy: 0.9772999882698059\n"
          ]
        }
      ],
      "source": [
        "# Do pass over test data and get test metrics\n",
        "# loss & then accuracy\n",
        "mod_eval = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f'Categorical Cross-Entropy Loss: {mod_eval[0]}\\nAccuracy: {mod_eval[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcFnMh2UEfgu",
        "outputId": "352011f5-8ea9-433e-e2d0-680045cb2a83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Array of class labels\n",
        "CLASSES = np.array(\n",
        "    [\n",
        "        \"0\",\n",
        "        \"1\",\n",
        "        \"2\",\n",
        "        \"3\",\n",
        "        \"4\",\n",
        "        \"5\",\n",
        "        \"6\",\n",
        "        \"7\",\n",
        "        \"8\",\n",
        "        \"9\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Get model preds\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "# Get model class pred\n",
        "preds_single = CLASSES[np.argmax(preds, axis=-1)]\n",
        "\n",
        "# Get true label\n",
        "actual_single = CLASSES[np.argmax(y_test, axis=-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "QVTa3I9uEfgu",
        "outputId": "1fbfc84a-d5e2-42b4-cb12-250c03e5747f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "n_to_show = 10  # Number of images to show\n",
        "\n",
        "# Get indices for values to show\n",
        "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
        "\n",
        "# Set up plot space\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "# Enumerate through indices and plot each\n",
        "for i, idx in enumerate(indices):\n",
        "    img = x_test[idx].reshape(28, 28)  # Reshape back to 28x28 for visualization\n",
        "\n",
        "    ax = fig.add_subplot(1, n_to_show, i + 1)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    # Determine color based on whether pred matches act\n",
        "    color = \"green\" if preds_single[idx] == actual_single[idx] else \"red\"\n",
        "\n",
        "    # Add text for prediction with color based on match\n",
        "    ax.text(\n",
        "        0.5,\n",
        "        -0.35,\n",
        "        \"pred = \" + str(preds_single[idx]),\n",
        "        fontsize=10,\n",
        "        ha=\"center\",\n",
        "        transform=ax.transAxes,\n",
        "        color=color  # Set color based on prediction correctness\n",
        "    )\n",
        "\n",
        "    # Add text for actual value\n",
        "    ax.text(\n",
        "        0.5,\n",
        "        -0.7,\n",
        "        \"act = \" + str(actual_single[idx]),\n",
        "        fontsize=10,\n",
        "        ha=\"center\",\n",
        "        transform=ax.transAxes\n",
        "    )\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(img, cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATING color coding\n",
        "\n",
        "indices = np.random.choice(range(len(x_test)), 10_000)\n",
        "\n",
        "green = 0\n",
        "red = 0\n",
        "\n",
        "# Enumerate through test data and compare\n",
        "for i in range(len(x_test)):\n",
        "    # Determine color based on whether pred matches act\n",
        "    color = \"green\" if preds_single[i] == actual_single[i] else \"red\"\n",
        "\n",
        "    if color == 'green':\n",
        "      green += 1\n",
        "    else:\n",
        "      red += 1\n",
        "\n",
        "print('Green total:', green)\n",
        "print('Red total:', red)\n",
        "print('Total in test set:', len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C4rZ9Hy7_0F",
        "outputId": "1bdb9bcb-148e-4d98-cb9e-7412dc602a59"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Green total: 9773\n",
            "Red total: 227\n",
            "Total in test set: 10000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}