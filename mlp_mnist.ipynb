{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_jeQy4REfgq"
      },
      "source": [
        "# Multilayer Perceptron (MLP) for MNIST Dataset\n",
        "\n",
        "In this notebook, we'll explore how to train a Multilayer Perceptron (MLP) on the popular MNIST dataset, which contains grayscale images of handwritten digits (0-9).\n",
        "\n",
        "A MLP is one of the most basic types of neural networks that you will encounter. They operate in a feed-forward (FFNN) fashion, with no sort of recurrent operation present. They are oftentimes called \"vanilla\" neural networks, due to them being thought of as a default style of network. They are also often called dense neural networks, due to the fact that the neurons are commonly fully connected to each other between hidden layers.\n",
        "\n",
        "Notebook inspired by [Generative Deep Learning: Teaching Machines to Paint, Write, Compose and Play](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1eqYgTDBEfgs"
      },
      "outputs": [],
      "source": [
        "# PACKAGE IMPORTS\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers, models, optimizers, utils, datasets\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "oEiMTL0rEfgt"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XdyJiAuMEfgt"
      },
      "outputs": [],
      "source": [
        "NUM_CLASSES = 10 # Constant; digits 0 - 9\n",
        "BATCH_SIZE = 32 # size of mini-batch\n",
        "NUM_EPOCHS = 10 # full passes through data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO9SV1UIEfgt"
      },
      "source": [
        "\n",
        "## 1. Prepare the Data\n",
        "\n",
        "We will load the MNIST dataset, which contains 60,000 training images and 10,000 test images of handwritten digits. Each image is 28x28 pixels, and the task is to classify them into 10 classes (digits 0-9).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcILgyBNEfgt",
        "outputId": "58a984cd-dd6b-4503-ec63-985fd3175589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Training data shape: (60000, 784)\n",
            "Training labels shape: (60000, 10)\n",
            "\n",
            "Test data shape: (10000, 784)\n",
            "Test labels shape: (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to have pixel values between 0 and 1\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "# -1 effectively tells Python to ignore batch dimension\n",
        "# 28*28 is flattening the image into a 1D vector\n",
        "x_train = x_train.reshape(-1, 28 * 28)\n",
        "x_test = x_test.reshape(-1, 28 * 28)\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Display train dat & label shape\n",
        "print(f\"Training data shape: {x_train.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "\n",
        "# Spacing\n",
        "print()\n",
        "\n",
        "# Display test dat & label shape\n",
        "print(f\"Test data shape: {x_test.shape}\")\n",
        "print(f\"Test labels shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGHHhnRWEfgt",
        "outputId": "af2eb3a7-ceb8-40cd-f5f5-ef735afd58b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Pixel Values:\n",
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            "  0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            "  0.96862745 0.49803922 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            "  0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.19215687\n",
            "  0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            "  0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            "  0.96862745 0.94509804 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            "  0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.04313726\n",
            "  0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.13725491 0.94509804\n",
            "  0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            "  0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            "  0.5882353  0.10588235 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            "  0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.15294118 0.5803922\n",
            "  0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            "  0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.07058824 0.67058825\n",
            "  0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            "  0.3137255  0.03529412 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            "  0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.53333336 0.99215686\n",
            "  0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n",
            "\n",
            "Label for first entry:\n",
            "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# Set NumPy to print the entire array\n",
        "np.set_printoptions(threshold=np.inf)\n",
        "\n",
        "# Normalized pixel values\n",
        "print('Normalized Pixel Values:')\n",
        "print(x_train[:1])\n",
        "\n",
        "print() # Spacing\n",
        "\n",
        "# First entry label\n",
        "print('Label for first entry:')\n",
        "print(y_train[:1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pti3LWjwEfgt"
      },
      "source": [
        "\n",
        "## 2. Build the Model\n",
        "We will build a simple Multilayer Perceptron (MLP) model with the following architecture:\n",
        "- Input layer: 784 (28x28) input neurons (one for each pixel in the MNIST image).\n",
        "- Two hidden layers with ReLU activation.\n",
        "- Output layer with 10 neurons (one for each class) using softmax activation.\n",
        "\n",
        "Here's how we can define this model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "FGvW1xHTEfgu",
        "outputId": "8ecc9901-4a50-4200-91e8-2d8cb5a54e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the MLP model\n",
        "model = Sequential([\n",
        "    # First hidden layer with 128 units\n",
        "    Dense(128, activation='relu', input_shape=(784,)),\n",
        "    # Second hidden layer with 64 units\n",
        "    Dense(64, activation='relu'),\n",
        "    # Output layer with 10 classes (digits 0-9)\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with categorical crossentropy and an optimizer\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Show model summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "hfyia5fPEfgu"
      },
      "source": [
        "## 3. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9pkGYrN3Efgu"
      },
      "outputs": [],
      "source": [
        "# Set up optimizer for backpropogation\n",
        "opt = optimizers.Adam(learning_rate=0.0005)\n",
        "\n",
        "# Compile model - get it ready for training\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=opt, metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzqx2CtyEfgu",
        "outputId": "72a6080b-03c7-422f-aa7a-9e53b4191f3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8498 - loss: 0.5394\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9621 - loss: 0.1256\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0843\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0629\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0443\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0378\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0312\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0218\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0200\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.0145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x793976df3580>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Fit model\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=BATCH_SIZE, # batch size for each mini-batch of data\n",
        "          epochs=NUM_EPOCHS, # 10 pass-throughs of the full data\n",
        "          shuffle=True # Shuffle data for better training\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "bv8uOT5_Efgu"
      },
      "source": [
        "## 4. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2YzCJ90Efgu",
        "outputId": "cdd303d2-28a0-4abe-d599-f193eca36115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.1109\n",
            "Categorical Cross-Entropy Loss: 0.08999170362949371\n",
            "Accuracy: 0.977400004863739\n"
          ]
        }
      ],
      "source": [
        "# Do pass over test data and get test metrics\n",
        "# loss & then accuracy\n",
        "mod_eval = model.evaluate(x_test, y_test)\n",
        "\n",
        "print(f'Categorical Cross-Entropy Loss: {mod_eval[0]}\\nAccuracy: {mod_eval[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcFnMh2UEfgu",
        "outputId": "bd10fc43-2a31-4c05-9526-f2622d809328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        }
      ],
      "source": [
        "# Array of class labels\n",
        "CLASSES = np.array(\n",
        "    [\n",
        "        \"0\",\n",
        "        \"1\",\n",
        "        \"2\",\n",
        "        \"3\",\n",
        "        \"4\",\n",
        "        \"5\",\n",
        "        \"6\",\n",
        "        \"7\",\n",
        "        \"8\",\n",
        "        \"9\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Get model preds\n",
        "preds = model.predict(x_test)\n",
        "\n",
        "# Get model class pred\n",
        "preds_single = CLASSES[np.argmax(preds, axis=-1)]\n",
        "\n",
        "# Get true label\n",
        "actual_single = CLASSES[np.argmax(y_test, axis=-1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "QVTa3I9uEfgu",
        "outputId": "f47d9912-5f80-42b0-c5f8-edc98e4df769"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "n_to_show = 10  # Number of images to show\n",
        "\n",
        "# Get indices for values to show\n",
        "indices = np.random.choice(range(len(x_test)), n_to_show)\n",
        "\n",
        "# Set up plot space\n",
        "fig = plt.figure(figsize=(15, 3))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
        "\n",
        "# Enumerate through indices and plot each\n",
        "for i, idx in enumerate(indices):\n",
        "    img = x_test[idx].reshape(28, 28)  # Reshape back to 28x28 for visualization\n",
        "\n",
        "    ax = fig.add_subplot(1, n_to_show, i + 1)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    # Determine color based on whether pred matches act\n",
        "    color = \"green\" if preds_single[idx] == actual_single[idx] else \"red\"\n",
        "\n",
        "    # Add text for prediction with color based on match\n",
        "    ax.text(\n",
        "        0.5,\n",
        "        -0.35,\n",
        "        \"pred = \" + str(preds_single[idx]),\n",
        "        fontsize=10,\n",
        "        ha=\"center\",\n",
        "        transform=ax.transAxes,\n",
        "        color=color  # Set color based on prediction correctness\n",
        "    )\n",
        "\n",
        "    # Add text for actual value\n",
        "    ax.text(\n",
        "        0.5,\n",
        "        -0.7,\n",
        "        \"act = \" + str(actual_single[idx]),\n",
        "        fontsize=10,\n",
        "        ha=\"center\",\n",
        "        transform=ax.transAxes\n",
        "    )\n",
        "\n",
        "    # Display the image\n",
        "    ax.imshow(img, cmap='gray')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VALIDATING color coding\n",
        "\n",
        "indices = np.random.choice(range(len(x_test)), 10_000)\n",
        "\n",
        "green = 0\n",
        "red = 0\n",
        "\n",
        "# Enumerate through test data and compare\n",
        "for i in range(len(x_test)):\n",
        "    # Determine color based on whether pred matches act\n",
        "    color = \"green\" if preds_single[i] == actual_single[i] else \"red\"\n",
        "\n",
        "    if color == 'green':\n",
        "      green += 1\n",
        "    else:\n",
        "      red += 1\n",
        "\n",
        "print('Green total:', green)\n",
        "print('Red total:', red)\n",
        "print('Total in test set:', len(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C4rZ9Hy7_0F",
        "outputId": "90acaeaa-5853-4885-be65-7de0f1c01298"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Green total: 9774\n",
            "Red total: 226\n",
            "Total in test set: 10000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}